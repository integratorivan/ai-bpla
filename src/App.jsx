import React, { useState, useEffect, useRef } from "react";
import * as tf from "@tensorflow/tfjs";
import "@tensorflow/tfjs-backend-webgl"; // set backend to webgl
import "@tensorflow/tfjs-backend-webgpu";
import Loader from "./components/loader";
import ButtonHandler from "./components/btn-handler";
import Statistics from "./components/statistics";
import VideoControls from "./components/video-controls";
import ModelSelector from "./components/model-selector";
import { detect, detectVideo } from "./utils/detect";
import "./style/App.css";
import "./style/model-selector.css";

const App = () => {
  const [loading, setLoading] = useState({ loading: true, progress: 0 }); // loading state
  const [model, setModel] = useState({
    net: null,
    inputShape: [1, 0, 0, 3],
  }); // init model & input shape
  const [selectedModel, setSelectedModel] = useState("yolov8n"); // default model
  const [streaming, setStreaming] = useState(null); // current streaming mode
  const [statistics, setStatistics] = useState({}); // detection statistics
  const [backendInfo, setBackendInfo] = useState(""); // backend information
  const [performanceInfo, setPerformanceInfo] = useState({ avgTime: 0, detectionCount: 0 }); // performance stats
  const [modelDetails, setModelDetails] = useState({ params: 0, layers: 0 }); // model details
  const [sidebarVisible, setSidebarVisible] = useState(false); // sidebar visibility for mobile

  // references
  const imageRef = useRef(null);
  const cameraRef = useRef(null);
  const videoRef = useRef(null);
  const canvasRef = useRef(null);

  // Handle detection statistics
  const handleDetection = (detectedObjects, detectionTime) => {
    setStatistics(prevStats => {
      const newStats = { ...prevStats };
      Object.entries(detectedObjects).forEach(([className, count]) => {
        newStats[className] = (newStats[className] || 0) + count;
      });
      return newStats;
    });

    // Update performance info if detection time is provided
    if (detectionTime !== undefined) {
      setPerformanceInfo(prev => {
        const newCount = prev.detectionCount + 1;
        const newAvgTime = ((prev.avgTime * prev.detectionCount) + detectionTime) / newCount;
        return {
          avgTime: newAvgTime,
          detectionCount: newCount
        };
      });
    }
  };

  // Clear statistics
  const clearStatistics = () => {
    setStatistics({});
    setPerformanceInfo({ avgTime: 0, detectionCount: 0 });
  };

  // Initialize TensorFlow.js with fallback
  const initializeTensorFlow = async () => {
        tf.setBackend("webgpu"); // set backend to webgpu
        await tf.ready();
  };

  // Load model function with error handling
  const loadModel = async (modelName) => {
    try {
      console.log(`üì¶ –ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏: ${modelName}`);
      setLoading({ loading: true, progress: 0 });
      
      const modelPath = `${window.location.href}/${modelName}_web_model/model.json`;
      console.log(`üìç –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏: ${modelPath}`);
      
      const yoloModel = await tf.loadGraphModel(
        modelPath,
        {
          onProgress: (fractions) => {
            setLoading({ loading: true, progress: fractions });
            console.log(`‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ ${modelName}: ${(fractions * 100).toFixed(1)}%`);
          },
        }
      );

      console.log(`‚úÖ –ú–æ–¥–µ–ª—å ${modelName} –∑–∞–≥—Ä—É–∂–µ–Ω–∞, —Ç–µ—Å—Ç–∏—Ä—É—é –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...`);
      console.log(`üìä –†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞ –º–æ–¥–µ–ª–∏: ${JSON.stringify(yoloModel.inputs[0].shape)}`);
      
      // –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ —Ç–æ–ø–æ–ª–æ–≥–∏–∏ –º–æ–¥–µ–ª–∏
      let layerCount = '–Ω/–¥';
      try {
        if (yoloModel.modelTopology && yoloModel.modelTopology.node_def) {
          layerCount = Object.keys(yoloModel.modelTopology.node_def).length;
        } else if (yoloModel.layers) {
          layerCount = yoloModel.layers.length;
        }
      } catch (e) {
        console.log(`‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ—ë–≤: ${e.message}`);
      }
      
      console.log(`‚öôÔ∏è –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ—ë–≤ –≤ –º–æ–¥–µ–ª–∏: ${layerCount}`);
      console.log(`üéØ –í—ã—Ö–æ–¥–Ω—ã–µ —Ç–µ–Ω–∑–æ—Ä—ã: ${yoloModel.outputs.length}`);

      // –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏
      try {
        const modelSize = yoloModel.getWeights().reduce((total, weight) => total + weight.size, 0);
        console.log(`üì¶ –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: ${(modelSize / 1000000).toFixed(1)}M`);
        setModelDetails({
          params: (modelSize / 1000000).toFixed(1),
          layers: layerCount
        });
      } catch (e) {
        console.log(`üì¶ –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—á–∏—Ç–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏: ${e.message}`);
        setModelDetails({ params: '–Ω/–¥', layers: layerCount });
      }

      // Test model execution with error handling
      try {
        const dummyInput = tf.ones(yoloModel.inputs[0].shape);
        const warmupResults = yoloModel.execute(dummyInput);
        tf.dispose([warmupResults, dummyInput]);
        
        setLoading({ loading: false, progress: 1 });
        setModel({
          net: yoloModel,
          inputShape: yoloModel.inputs[0].shape,
        });

        console.log(`üéâ –ú–æ–¥–µ–ª—å ${modelName} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ —Å ${tf.getBackend()} backend`);
        setBackendInfo(`${tf.getBackend().toUpperCase()} (–º–æ–¥–µ–ª—å: ${modelName})`);
      } catch (executionError) {
        console.error('Model execution failed with current backend:', executionError);
        
        // If WebGL execution fails, try switching to CPU
        if (tf.getBackend() === 'webgl') {
          console.log('Switching to CPU backend due to execution error...');
          await tf.setBackend('cpu');
          await tf.ready();
          setBackendInfo(`CPU (${tf.getBackend()}) - WebGL execution failed (–º–æ–¥–µ–ª—å: ${modelName})`);
          
          // Retry model execution with CPU
          const dummyInput = tf.ones(yoloModel.inputs[0].shape);
          const warmupResults = yoloModel.execute(dummyInput);
          tf.dispose([warmupResults, dummyInput]);
          
          setLoading({ loading: false, progress: 1 });
          setModel({
            net: yoloModel,
            inputShape: yoloModel.inputs[0].shape,
          });
          
          console.log(`Model ${modelName} loaded successfully with CPU backend after WebGL failure`);
        } else {
          throw executionError;
        }
      }
    } catch (error) {
      console.error(`‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ ${modelName}:`, error);
      setLoading({ loading: false, progress: 0 });
      
      // User-friendly error message
      let errorMessage = `–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ ${modelName}`;
      if (error.message.includes('Failed to link vertex and fragment shaders')) {
        errorMessage += '\n\n–ü—Ä–æ–±–ª–µ–º–∞ —Å WebGL –Ω–∞ –≤–∞—à–µ–π —Å–∏—Å—Ç–µ–º–µ. –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É - –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω CPU —Ä–µ–∂–∏–º.';
      } else if (error.message.includes('404')) {
        errorMessage += '\n\n–§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –≤ –ø–∞–ø–∫—É public.';
      } else {
        errorMessage += `\n\n–î–µ—Ç–∞–ª–∏: ${error.message}`;
      }
      
      alert(errorMessage);
    }
  };

  // Handle model change
  const handleModelChange = (newModel) => {
    if (newModel !== selectedModel && !loading.loading) {
      setSelectedModel(newModel);
      setLoading({ loading: true, progress: 0 });
      clearStatistics(); // Clear stats when changing model
      loadModel(newModel);
    }
  };

  // Determine current streaming mode
  const getCurrentStreamingMode = () => {
    if (imageRef.current?.style.display === "block") return "image";
    if (videoRef.current?.style.display === "block") return "video";
    if (cameraRef.current?.style.display === "block") return "camera";
    return null;
  };

  // Load initial model
  useEffect(() => {
    initializeTensorFlow().then(() => {
      loadModel(selectedModel);
    }).catch((error) => {
      console.error('TensorFlow initialization failed:', error);
      setLoading({ loading: false, progress: 0 });
      alert('–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ TensorFlow.js. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É.');
    });
  }, [selectedModel]);

  // Update streaming state when components mount/unmount
  useEffect(() => {
    const interval = setInterval(() => {
      setStreaming(getCurrentStreamingMode());
    }, 100);

    return () => clearInterval(interval);
  }, []);


  return (
    <div className="App">
      {loading.loading && <Loader>–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {selectedModel}... {(loading.progress * 100).toFixed(2)}%</Loader>}
      
      <div className="main-layout">
        {/* –õ–µ–≤–∞—è –æ–±–ª–∞—Å—Ç—å - –≤–∏–¥–µ–æ */}
        <div className="video-area">
          <div className="content">
            <img
              src="#"
              ref={imageRef}
              onLoad={() => detect(imageRef.current, model, canvasRef.current, () => {}, handleDetection)}
            />
            <video
              autoPlay
              muted
              playsInline
              ref={cameraRef}
              onPlay={() => detectVideo(cameraRef.current, model, canvasRef.current, handleDetection)}
            />
            <video
              autoPlay
              muted
              playsInline
              ref={videoRef}
              onPlay={() => detectVideo(videoRef.current, model, canvasRef.current, handleDetection)}
            />
            <canvas width={model.inputShape[1]} height={model.inputShape[2]} ref={canvasRef} />
          </div>
          
          <VideoControls 
            videoRef={videoRef} 
            isVideoPlaying={streaming === "video"} 
          />
        </div>

        {/* –ü—Ä–∞–≤–∞—è –æ–±–ª–∞—Å—Ç—å - –∫–æ–Ω—Ç—Ä–æ–ª—ã */}
        <div className="control-area">
          {/* –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –≤–≤–µ—Ä—Ö—É */}
          <ModelSelector 
            selectedModel={selectedModel}
            onModelChange={handleModelChange}
            isLoading={loading.loading}
          />
          
          {/* –ö–æ–Ω—Ç—Ä–æ–ª—ã */}
          <ButtonHandler
            imageRef={imageRef}
            cameraRef={cameraRef}
            videoRef={videoRef}
            streaming={streaming}
            setStreaming={setStreaming}
          />
          
          {/* –ö–æ–º–ø–∞–∫—Ç–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ */}
          <Statistics 
            statistics={statistics} 
            onClearStats={clearStatistics} 
          />
        </div>
      </div>
    </div>
  );
};

export default App;